experiment:
    name: xtx_precision_perf
    seed: 1234
    repeats: 3
    warmup_iters: 1

matrix:
    row: 150000
    col: 10000
    dtype_storage: fp32
    layout: row_major

numa:
    gpu_local_node: 1
    remote_node: 0
    split_ratio: 0.5

chunking: 
    rows_per_chunk: 300000
    pinned_buffers: 1
    pinned_buffer_gb: 12

gpu:
    device_id: 0
    backend: cublas
    use_streams: true
    streams: 2

modes:
    - name: fp32
      input_dtype: fp32
      compute: fp32
      accumulate: fp32
      cublas_math_mode: DEFAULT

    - name: tf32
      input_dtype: fp32
      compute: tf32
      accumulate: fp32
      cublas_math_mode: TF32

    - name: bf16
      input_dtype: bf16
      compute: tensorcore
      accumulate: fp32
      cast_on_gpu: true

    - name: fp16
      input_dtype: fp16
      compute: tensorcore
      accumulate: fp32
      cast_on_gpu: true

# gemm / syrk
xtx:
    algorithm: syrk # / gemm
    triangle: lower
    alpha: 1.0
    beta_first: 0.0
    beta_rest: 1.0

metrics:
    time_gpu_only: true
    include_h2d: true
    compute_tflops: true
    reference_mode: fp32
    error_norm: frobenius

output: 
    result_csv: result.csv
    log_level: info
